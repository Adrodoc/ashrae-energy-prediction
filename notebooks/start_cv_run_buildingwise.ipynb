{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question include new mode namley start_cv_run_building_id\n",
    "# or introduces new parameter that can be use in the config file\n",
    "# the latter is probably better\n",
    "# pseudo code:\n",
    "# start_cv_run_buidlingwise:\n",
    "# if mode = group_cv_building\n",
    "    # meter0 = train_df.meter == 0 returns logical vector\n",
    "    # train_df = train_df meter0 rows\n",
    "    # label = label aber nur meter 0 rows\n",
    "# group kfold\n",
    "# define the groups array by building_id\n",
    "# and run the cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building_id keepen auch wenn dropped in make features\n",
    "# if cv grouped on building id\n",
    "# and in drop vector\n",
    "# then delete it from drop vector\n",
    "\n",
    "# summ we have a vector containing the building id\n",
    "# this vector indicates which variables will be dropped\n",
    "# but we nee building id to group the folds in the cross validation\n",
    "# first solution see above\n",
    "#\n",
    "# also it needs to be dropped again in the cross validation function so taht it is\n",
    "# not inculded in the parameeters for tehe mdoel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = adden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(mode, input_filepath, output_filepath):\n",
    "    \"\"\"\n",
    "    Collects prepared data and starts training an LightGBM model. Parameters\n",
    "    can be specified by editing src/config.yml.\n",
    "    :param mode: Specifies mode to run. Options are full (no validation set,\n",
    "    single fold), cv (cross validation), by_meter (training by meter type),\n",
    "    by_building (training by building id).\n",
    "    :param input_filepath: Directory that contains the processed data.\n",
    "    :param output_filepath: Directory that will contain the trained models.\n",
    "    \"\"\"\n",
    "    random.seed(1337)\n",
    "    with timer(\"Loading processed training data\"):\n",
    "        train_df, label = load_processed_training_data(input_filepath)\n",
    "\n",
    "    ###########################################################################\n",
    "    # DEFINE PARAMETERS FOR THE LGBM MODEL                                     #\n",
    "    ###########################################################################\n",
    "    with open(\"src/config.yml\", 'r') as ymlfile:\n",
    "        cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "    params = cfg[\"lgbm_params\"]\n",
    "    num_boost_round = cfg[\"lgbm_num_boost_round\"]\n",
    "    early_stopping_rounds = cfg[\"lgbm_early_stopping_rounds\"]\n",
    "    splits = cfg[\"lgbm_splits_for_cv\"]\n",
    "    verbose_eval = cfg[\"lgbm_verbose_eval\"]\n",
    "    grouped_on_building = cfg[\"lgbm_cv_grouped_on_building\"]\n",
    "    ###########################################################################\n",
    "\n",
    "    if mode == \"full\":\n",
    "        start_full_training_run(train_df, label, params, verbose_eval,\n",
    "                                num_boost_round, early_stopping_rounds,\n",
    "                                output_filepath)\n",
    "    elif mode == \"cv\":\n",
    "        start_cv_run(train_df, label, params, splits, verbose_eval,\n",
    "                     num_boost_round, early_stopping_rounds, output_filepath, grouped_on_building)\n",
    "    elif mode == \"by_meter\":\n",
    "        start_full_by_meter_run(train_df, label, params, verbose_eval,\n",
    "                                num_boost_round, early_stopping_rounds, output_filepath)\n",
    "    elif mode == \"by_building\":\n",
    "        start_full_by_building_run(train_df, label, params, splits, verbose_eval,\n",
    "                                   num_boost_round, early_stopping_rounds, output_filepath)\n",
    "    else:\n",
    "        raise ValueError(\"Choose a valid mode: 'full', 'cv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elif mode == \"cv\":\n",
    "    start_cv_run(train_df, label, params, splits, verbose_eval,\n",
    "    num_boost_round, early_stopping_rounds, output_filepath, grouped_on_building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_cv_run(train_df, label, params, splits, verbose_eval,\n",
    "                 num_boost_round, early_stopping_rounds, output_filepath,\n",
    "                 grouped_on_building):\n",
    "    \"\"\"\n",
    "    Starts a Cross Validation Run with the parameters provided.\n",
    "    Scores will be documented and models will be saved.\n",
    "    :param train_df: DataFrame which contains the training data.\n",
    "    :param label: A vector which contains the labels of the training data.\n",
    "    :param params: Dictionary with the model parameters\n",
    "    :param splits: Integer describing the number of folds / splitting fraction.\n",
    "    :param verbose_eval: The interval where training information is printed\n",
    "    to console.\n",
    "    :param num_boost_round: Maximum number of rounds / estimators for the training.\n",
    "    :param early_stopping_rounds: If no improvement of the validation score in\n",
    "    n rounds occur, the training will be stopped.\n",
    "    :param output_filepath: Directory that will contain the trained models.\n",
    "    \"\"\"\n",
    "    if grouped_on_building:\n",
    "        if not 'building_id' in train_df.columns:\n",
    "            raise ValueError(\n",
    "                \"For grouped cv, the cross validation is grouped on building_id.\"\n",
    "                \"Therefore it must be excluded from the drop section in the config file.\"\n",
    "                \"Note that the building_id is still not included in the model,\"\n",
    "                \"it is needed for specifying the folds only and will be dropped afterwards.\")\n",
    "        output_filepath = output_filepath + \"grouped_cv\"\n",
    "        is_meter0 = (train_df.meter == 0).values\n",
    "        train_df = train_df.iloc[is_meter0,]\n",
    "        label = label.iloc[is_meter0,]\n",
    "        groups = train_df.building_id\n",
    "        train_df = drop_columns(train_df, 'building_id')\n",
    "        gkf = GroupKFold(n_splits = splits)\n",
    "        indices = gkf.split(train_df, label, groups)\n",
    "    else:\n",
    "        output_filepath = output_filepath + \"_cv\"\n",
    "        kf = Kfold(n_splits = splits, shuffle = False, random = state = 1337)\n",
    "        indices = kf.split(train_df, label)\n",
    "    cv_results = []\n",
    "    with timer(\"Performing \" + str(splits) + \" fold cross-validation\"):\n",
    "        for i, (train_index, test_index) in enumerate(indices):\n",
    "            with timer(\"~~~~ Fold %d of %d ~~~~\" % (i + 1, splits)):\n",
    "                x_train, x_valid = train_df.iloc[train_index], train_df.iloc[test_index]\n",
    "                y_train, y_valid = label[train_index], label[test_index]\n",
    "\n",
    "                train_lgb_df = lgb.Dataset(data=x_train, label=y_train)\n",
    "                valid_lgb_df = lgb.Dataset(data=x_valid, label=y_valid)\n",
    "\n",
    "                valid_sets = [train_lgb_df, valid_lgb_df]\n",
    "                evals_result = dict()\n",
    "                lgbm_model = lgb.train(params=params,\n",
    "                                       train_set=train_lgb_df,\n",
    "                                       num_boost_round=num_boost_round,\n",
    "                                       valid_sets=valid_sets,\n",
    "                                       valid_names=[\"train_loss\", \"eval\"],\n",
    "                                       verbose_eval=verbose_eval,\n",
    "                                       evals_result=evals_result,\n",
    "                                       early_stopping_rounds=early_stopping_rounds)\n",
    "                save_model(output_filepath, lgbm_model)\n",
    "\n",
    "                cv_results.append(evals_result)\n",
    "        evaluate_cv_results(cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KFold in module sklearn.model_selection._split:\n",
      "\n",
      "class KFold(_BaseKFold)\n",
      " |  KFold(n_splits='warn', shuffle=False, random_state=None)\n",
      " |  \n",
      " |  K-Folds cross-validator\n",
      " |  \n",
      " |  Provides train/test indices to split data in train/test sets. Split\n",
      " |  dataset into k consecutive folds (without shuffling by default).\n",
      " |  \n",
      " |  Each fold is then used once as a validation while the k - 1 remaining\n",
      " |  folds form the training set.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=3\n",
      " |      Number of folds. Must be at least 2.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          ``n_splits`` default value will change from 3 to 5 in v0.22.\n",
      " |  \n",
      " |  shuffle : boolean, optional\n",
      " |      Whether to shuffle the data before splitting into batches.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default=None\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`. Used when ``shuffle`` == True.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.model_selection import KFold\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      " |  >>> y = np.array([1, 2, 3, 4])\n",
      " |  >>> kf = KFold(n_splits=2)\n",
      " |  >>> kf.get_n_splits(X)\n",
      " |  2\n",
      " |  >>> print(kf)  # doctest: +NORMALIZE_WHITESPACE\n",
      " |  KFold(n_splits=2, random_state=None, shuffle=False)\n",
      " |  >>> for train_index, test_index in kf.split(X):\n",
      " |  ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  ...    X_train, X_test = X[train_index], X[test_index]\n",
      " |  ...    y_train, y_test = y[train_index], y[test_index]\n",
      " |  TRAIN: [2 3] TEST: [0 1]\n",
      " |  TRAIN: [0 1] TEST: [2 3]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The first ``n_samples % n_splits`` folds have size\n",
      " |  ``n_samples // n_splits + 1``, other folds have size\n",
      " |  ``n_samples // n_splits``, where ``n_samples`` is the number of samples.\n",
      " |  \n",
      " |  Randomized CV splitters may return different results for each call of\n",
      " |  split. You can make the results identical by setting ``random_state``\n",
      " |  to an integer.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  StratifiedKFold\n",
      " |      Takes group information into account to avoid building folds with\n",
      " |      imbalanced class distributions (for binary or multiclass\n",
      " |      classification tasks).\n",
      " |  \n",
      " |  GroupKFold: K-fold iterator variant with non-overlapping groups.\n",
      " |  \n",
      " |  RepeatedKFold: Repeats K-Fold n times.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KFold\n",
      " |      _BaseKFold\n",
      " |      BaseCrossValidator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_splits='warn', shuffle=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKFold:\n",
      " |  \n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |  \n",
      " |  split(self, X, y=None, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training data, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          The target variable for supervised learning problems.\n",
      " |      \n",
      " |      groups : array-like, with shape (n_samples,), optional\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |      \n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([1, 2, 3, 4])\n",
    "groups = np.array([0, 0, 2, 2])\n",
    "group_kfold = GroupKFold(n_splits=2)\n",
    "group_kfold.get_n_splits(X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupKFold(n_splits=2)\n"
     ]
    }
   ],
   "source": [
    "print(group_kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1] TEST [2 3]\n",
      "TRAIN: [2 3] TEST [0 1]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in group_kfold.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_index, \"TEST\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, (array([0, 1]), array([2, 3]))]\n",
      "[1, (array([2, 3]), array([0, 1]))]\n"
     ]
    }
   ],
   "source": [
    " for a, (b, c) in enumerate(group_kfold.split(X, y, groups)):\n",
    "        print([a, (b,c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../src/config.yml\", 'r') as ymlfile:\n",
    "        cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timestamp',\n",
       " 'month',\n",
       " 'sea_level_pressure',\n",
       " 'wind_direction',\n",
       " 'wind_speed',\n",
       " 'timezone',\n",
       " 'country_code',\n",
       " 'location',\n",
       " 'site_id',\n",
       " 'building_id']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg[\"drop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
