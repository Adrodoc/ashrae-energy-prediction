{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fancyimpute import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    min_date = \"2018-01-01 00:00:00\"\n",
    "    max_date = \"2018-01-02 00:00:00\"\n",
    "    date_range = pd.date_range(start=min_date, end=max_date, freq=\"1H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 01:00:00',\n",
       "               '2018-01-01 02:00:00', '2018-01-01 03:00:00',\n",
       "               '2018-01-01 04:00:00', '2018-01-01 05:00:00',\n",
       "               '2018-01-01 06:00:00', '2018-01-01 07:00:00',\n",
       "               '2018-01-01 08:00:00', '2018-01-01 09:00:00',\n",
       "               '2018-01-01 10:00:00', '2018-01-01 11:00:00',\n",
       "               '2018-01-01 12:00:00', '2018-01-01 13:00:00',\n",
       "               '2018-01-01 14:00:00', '2018-01-01 15:00:00',\n",
       "               '2018-01-01 16:00:00', '2018-01-01 17:00:00',\n",
       "               '2018-01-01 18:00:00', '2018-01-01 19:00:00',\n",
       "               '2018-01-01 20:00:00', '2018-01-01 21:00:00',\n",
       "               '2018-01-01 22:00:00', '2018-01-01 23:00:00',\n",
       "               '2018-01-02 00:00:00'],\n",
       "              dtype='datetime64[ns]', freq='H')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.DataFrame({\"timestamp\": date_range})\n",
    "weather_imputed = pd.DataFrame(columns=[\"timestamp\", \"site_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create perfect timeline without missing hours\n",
    "for site in range(2):\n",
    "    date_range[\"site_id\"] = site\n",
    "    weather_imputed = weather_imputed.append(date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01 05:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-01 06:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-01 07:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-01 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-01 10:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-01 11:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-01 12:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-01 13:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-01 14:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-01 15:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-01 16:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-01 17:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-01 18:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-01 19:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-01 20:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-01 21:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-01-01 22:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-01-01 23:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-01 05:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-01 07:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-01 10:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-01 11:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-01 12:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-01 13:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-01 14:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-01 15:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-01 17:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-01 18:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-01 19:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-01 20:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-01 21:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-01-01 22:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-01-01 23:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp site_id\n",
       "0  2018-01-01 00:00:00       0\n",
       "1  2018-01-01 01:00:00       0\n",
       "2  2018-01-01 02:00:00       0\n",
       "3  2018-01-01 03:00:00       0\n",
       "4  2018-01-01 04:00:00       0\n",
       "5  2018-01-01 05:00:00       0\n",
       "6  2018-01-01 06:00:00       0\n",
       "7  2018-01-01 07:00:00       0\n",
       "8  2018-01-01 08:00:00       0\n",
       "9  2018-01-01 09:00:00       0\n",
       "10 2018-01-01 10:00:00       0\n",
       "11 2018-01-01 11:00:00       0\n",
       "12 2018-01-01 12:00:00       0\n",
       "13 2018-01-01 13:00:00       0\n",
       "14 2018-01-01 14:00:00       0\n",
       "15 2018-01-01 15:00:00       0\n",
       "16 2018-01-01 16:00:00       0\n",
       "17 2018-01-01 17:00:00       0\n",
       "18 2018-01-01 18:00:00       0\n",
       "19 2018-01-01 19:00:00       0\n",
       "20 2018-01-01 20:00:00       0\n",
       "21 2018-01-01 21:00:00       0\n",
       "22 2018-01-01 22:00:00       0\n",
       "23 2018-01-01 23:00:00       0\n",
       "24 2018-01-02 00:00:00       0\n",
       "0  2018-01-01 00:00:00       1\n",
       "1  2018-01-01 01:00:00       1\n",
       "2  2018-01-01 02:00:00       1\n",
       "3  2018-01-01 03:00:00       1\n",
       "4  2018-01-01 04:00:00       1\n",
       "5  2018-01-01 05:00:00       1\n",
       "6  2018-01-01 06:00:00       1\n",
       "7  2018-01-01 07:00:00       1\n",
       "8  2018-01-01 08:00:00       1\n",
       "9  2018-01-01 09:00:00       1\n",
       "10 2018-01-01 10:00:00       1\n",
       "11 2018-01-01 11:00:00       1\n",
       "12 2018-01-01 12:00:00       1\n",
       "13 2018-01-01 13:00:00       1\n",
       "14 2018-01-01 14:00:00       1\n",
       "15 2018-01-01 15:00:00       1\n",
       "16 2018-01-01 16:00:00       1\n",
       "17 2018-01-01 17:00:00       1\n",
       "18 2018-01-01 18:00:00       1\n",
       "19 2018-01-01 19:00:00       1\n",
       "20 2018-01-01 20:00:00       1\n",
       "21 2018-01-01 21:00:00       1\n",
       "22 2018-01-01 22:00:00       1\n",
       "23 2018-01-01 23:00:00       1\n",
       "24 2018-01-02 00:00:00       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Takes an dataframe as argument and adjusts the datatypes of the respective\n",
    "    columns to reduce memory allocation\n",
    "    \"\"\"\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if (c_min > np.iinfo(np.int8).min and\n",
    "                        c_max < np.iinfo(np.int8).max):\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif (c_min > np.iinfo(np.int16).min and\n",
    "                      c_max < np.iinfo(np.int16).max):\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif (c_min > np.iinfo(np.int32).min and\n",
    "                      c_max < np.iinfo(np.int32).max):\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif (c_min > np.iinfo(np.int64).min and\n",
    "                      c_max < np.iinfo(np.int64).max):\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (c_min > np.finfo(np.float16).min and\n",
    "                        c_max < np.finfo(np.float16).max):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (c_min > np.finfo(np.float32).min and\n",
    "                      c_max < np.finfo(np.float32).max):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    reduced_mem = 100 * (start_mem - end_mem) / start_mem\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'\n",
    "              .format(end_mem, reduced_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_weather_data(data_frame):\n",
    "    data_frame[\"timestamp\"] = pd.to_datetime(data_frame[\"timestamp\"])\n",
    "    min_date = data_frame[\"timestamp\"].dropna().min()\n",
    "    max_date = data_frame[\"timestamp\"].dropna().max()\n",
    "    date_range = pd.date_range(start=min_date, end=max_date, freq=\"1H\")\n",
    "    date_range = pd.to_datetime(date_range)\n",
    "    date_range = pd.DataFrame({\"timestamp\": date_range})\n",
    "    weather_imputed = pd.DataFrame(columns=[\"timestamp\", \"site_id\"])\n",
    "\n",
    "    # Create perfect timeline without missing hours\n",
    "    for site in data_frame[\"site_id\"].unique():\n",
    "        date_range[\"site_id\"] = site\n",
    "        weather_imputed = weather_imputed.append(date_range)\n",
    "\n",
    "    # Join with existing weather data\n",
    "    weather_imputed = weather_imputed.merge(data_frame, left_on=[\"site_id\", \"timestamp\"], right_on=[\"site_id\", \"timestamp\"],\n",
    "                                  how=\"left\")\n",
    "\n",
    "    # Preserve data_frame data before transforming\n",
    "    weather_cols = weather_imputed.columns.values\n",
    "    weather_timestamp = weather_imputed[\"timestamp\"]\n",
    "    weather_site_ids = weather_imputed[\"site_id\"]\n",
    "\n",
    "    # Scale data for KNN\n",
    "    date_delta = pd.datetime.now() - weather_imputed[\"timestamp\"]\n",
    "    weather_imputed[\"timestamp\"] = date_delta.dt.total_seconds()\n",
    "    scaler = StandardScaler()\n",
    "    weather_imputed = scaler.fit_transform(weather_imputed)\n",
    "\n",
    "    # Impute missing values\n",
    "    weather_imputed = KNN(5).fit_transform(weather_imputed)\n",
    "\n",
    "    # Rescale\n",
    "    weather_imputed = scaler.inverse_transform(weather_imputed)\n",
    "\n",
    "    # Assemble final weather frame\n",
    "    weather_final = pd.DataFrame(data=weather_imputed, columns=weather_cols)\n",
    "    weather_final[\"timestamp\"] = weather_timestamp\n",
    "    weather_final[\"site_id\"] = weather_site_ids\n",
    "\n",
    "    return weather_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"../data/raw/weather_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'memory_usage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3453b0840148>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimpute_weather_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-d6fc60f3ca62>\u001b[0m in \u001b[0;36mimpute_weather_data\u001b[0;34m(data_frame)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Impute missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mweather_imputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_mem_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather_imputed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mweather_imputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather_imputed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6ddbe9bfb6f3>\u001b[0m in \u001b[0;36mreduce_mem_usage\u001b[0;34m(df, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m      6\u001b[0m     \u001b[0mnumerics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'int16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'float64'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mstart_mem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcol_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'memory_usage'"
     ]
    }
   ],
   "source": [
    "impute_weather_data(weather)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
